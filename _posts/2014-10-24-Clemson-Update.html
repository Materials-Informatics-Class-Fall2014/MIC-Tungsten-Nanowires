---
layout: post
title: Clemson Project Progress Report
author: jallen30gt
date:   2014-10-25 00:30:00
tagline: Presentation Matlab results from first pre-processing and image filtering attempts
latex: true

references:
-  http://imagej.nih.gov/ij/
-  http://www.originlab.com/doc/Origin-Help/Smooth-Algorithm
-  http://www.csse.uwa.edu.au/~pk/Research/MatlabFns/Spatial/derivative7.m # A stable derivative function
-  http://www.mathworks.com/help/images/ref/medfilt2.html # Median Filter Documentation
-  http://www.mathworks.com/help/images/ref/imdilate.html
-  http://terpconnect.umd.edu/~toh/spectrum/TOC.html
-  http://awhite40.github.io/MIC-Modeling-Polymer-Composites/2014/10/15/Segmentation-via-Gaussian-Likelihood-Approximation.html
-  http://materials-informatics-lab.github.io/2014/10/14/Image-Segmentation.html
-  http://jallen30gt.github.io/MIC-Tungsten-Nanowires/2014/09/26/Interface-Analysis.html
---

# Initial Surface Analysis

Initial processing of images was conducted using [Image J](http://imagej.nih.gov/ij/), an image software package developed at
the National Institute of Health.  All images have 1024 rows of pixels and 1024 columns of pixels with each pixel representing
an area of approximately 38.9 nm by 38.9 nm.  [Line plots](http://www.icoachmath.com/math_dictionary/line_plot.html)
were created to measure the inverted gray scale signal intensities of all pixels across the entire width (all pixel columns) 
of the image and averaged across pixel rows 330 - 370.  As the [2-D tomography](http://en.wikipedia.org/wiki/Electron_tomography) data is a measure of the intensities of detected electrons 
through the material, it is exptected that the line plots will yield information regarding the transition zones around the 
surface of the tungsten wire sample and the evolvig tungsten-trioxide-hydrate layer.  Below is the initial line diagrams 
(using the raw data) for the sample at 0%, 50% and 100% completion through the tungsten-trioxide-hydrate growth process.

<br>

<iframe src="//www.slideshare.net/slideshow/embed_code/39731430" width="476" height="400" frameborder="0" marginwidth="0" marginheight="0" scrolling="no"></iframe>

<br>

As can be seen from the line plots, the data is quite noisey (and significantly so towards the edge of the images).  This is 
important as this noise becomes relevant and needs to be reduced with regards to further image processing.  


## Refining the Level of Analysis 

A [Matlab code](https://gist.github.com/jallen30gt/8254e9ea2f938363dc0b) was developed to refine the initial processing of 
images. The code was written with three simple objectives in mind:

1.  [Smooth](http://en.wikipedia.org/wiki/Smoothing) the noise in images (done with a simple [adjacent point averaging](http://www.originlab.com/doc/Origin-Help/Smooth-Algorithm) at 10 and 500 times application).
    <br>
            $$x_{avg} = \frac{x_{i+1} + x_{i-1}}{2}$$
    <br>
    <br>
    Where:  $$x_{i+1}= data at column (i+1), x_{i-1}= data at column (i-1)$$ 
    <br>
    <br>
2.  Find the [First Derivative](http://en.wikipedia.org/wiki/Finite_difference#Relation_with_derivatives) (numerical using centered finite-divided-difference formulas)
    <br>
            $$f^{'}(x_i)=\frac{-f(x_{i+2})+8f(x_{i+1})-8f(x_{i-1})+f(x_{i-2})}{12h}$$
    <br>
    <br>
    Where:  $$x_{i+2}= data at column (i+2), x_{i+1}= data at column (i+1), x_{i-1} = data at column (i-1), x_{i-2}= data at column (i-2), h=1$$ 
    <br>
    <br>
3.  Find the [Second Derivative](http://en.wikipedia.org/wiki/Finite_difference#Relation_with_derivatives) (numerical using centered finite-divided-difference formulas)
    <br>
            $$f^{''}(x_i)=\frac{-f(x_{i+2})+16f(x_{i+1})-30f(x_i)+16(x_{i-1})-f(x_{i-2})}{12h^2}$$
    <br>
    <br>
    Where:  $$x_{i+2}= data at column (i+2), x_{i+1}= data at column (i+1), x_{i}= data at column (i), x_{i-1} = data at column (i-1), x_{i-2}= data at column (i-2), h=1$$ 
    
<br>
<table>
<tr>
  <td align="center">The results shown below are for smoothing applied <b>10 times</b>:</td>
  <td align="center">The results shown below are for smoothing applied <b>500 times</b>:</td>
</tr>
  <tr>
    <td><iframe src="//www.slideshare.net/slideshow/embed_code/39731450" width="476" height="400" frameborder="0" marginwidth="0" marginheight="0" scrolling="no"></iframe></td>
    <td><iframe src="//www.slideshare.net/slideshow/embed_code/39731465" width="476" height="400" frameborder="0" marginwidth="0" marginheight="0" scrolling="no"></iframe></td>
  </tr>
</table>

<br>

## What Information was Garnered?

Application of the simple smoothing algorithm 10 times did a sufficient job of smoothing the function.  However, the first and 
second derivative algorithms are much more sensitive and need higher applications of smoothing as can be seen in the level of
residual noise in the second first and second derivative plots.  From the smoothed data plot at 0% completion (time = 0s), 
there are two distinct slope regions around the transition region.  The first is of constant slope that appears to indicate the 
boundary between tungsten the potassium hydroxide (KOH) solution.  The second appears due to an unexplained image artifact that 
appears to evolve throughout the series of images; attempts are made to disregard this feature.  The first derivative of this data
clearly indicates one prominent peak around the transition region. It was also found that at this point in time, the second 
derivative of the data may not yield any important information and will not be discussed further.

The smoothed data plot at 50% completion (time = 78s) starts to show signs of deviation from linearity in the slope region.  Another, 
smaller, slope deviation, is also highlighted from the earlier mentioned unexplained image artifact.  Interestingly, the first
derivative of this data shows signs of peak splitting which appears to fit nicely with a possible developing two boundary region.
Similar trends appear for the smoothed data plot at 100% completion (time = 155 seconds) which shows three prominent slopes and the 
first derivative of this data showing three peaks which fit nicely with a possible three boundary region.

Application of the simple smoothing algorithm 500 times did a very nice job of smoothing the data, but eliminates all of the interesting features of the plots.  Over-smoothing 
tends to eliminate adjacent (split) peaks and tends to move slopes from the raw data towards the same value.       

## Further Refinement of Image Processing

A second [Matlab code](https://github.com/jallen30gt/MIC-Tungsten-Nanowires/blob/gh-pages/StartProj.m) was created in an attempt
to identify the possible interfaces in the data images. This program advances some of the mathematical techniques used from the 
previous code and was written in collaboration with Tony Fast. This code was written to advance the image analysis and the 
important features are:


1.  [Matlab's 2-D median filtering](http://www.mathworks.com/help/images/ref/medfilt2.html) applied to smooth data
2.  [Derivative7](http://www.csse.uwa.edu.au/~pk/Research/MatlabFns/Spatial/derivative7.m) function was used to find the first derivatives
3.  [Matlab's imdilate function](http://www.mathworks.com/help/images/ref/imdilate.html) was used to [dialate](http://en.wikipedia.org/wiki/Dilation_(morphology))(i.e., find local maximum values) images
4.  Peaks were identified through dilation of the images and the peaks mapped to and identified on the original images 

<br>
The outputs of this algorithm can be seen below for data at 0% (time = 1s), approximately 50% (times = 76-82s) and 100% completion
(time - 155s).  Shown are the peaks of the first derivatives of the data taken acorss the width of each image for each
individual row of the images (not averaged down each row such as was conducted in earlier analysis).  Each first derivative 
peak (in a given row) is then mapped onto the image at the column position at which the peak was located.  As a point of 
clarification, images are rotated 90 degrees counterclockwise from their initial orientation (as shown earlier) 
and are cropped around the boundary region in an attempt to reduce the high noise levels (discussed earlier) at the edges 
of the edges of the images. Thus, when the term row or column is used here, it is meant in relation to the original orienations
shown earlier:
<br>
<br>

<iframe src="//www.slideshare.net/slideshow/embed_code/39630963" width="476" height="400" frameborder="0" marginwidth="0" marginheight="0" scrolling="no"></iframe>

<br>

Early in the time evolution (time = 0s), it can be seen that there is a large spread of data points on one side of the image.
This is attributed to the way in which the image was cropped for analysis.  As can be seen, the area with the large spread of 
data is mostly tungsten (dark) with very little Pottasium Hydroxide (KOH, light region).  This essentially distributes the first 
derivative data across the image in a way that there is a higher probability of finding a peak in a dark region than anywhere 
else.  The fact that the peaks agglomerate around the transition region in the areas of the image that are more balanced
with light and dark regions leads creedence to this line of thinking.

Very interesting are the distributions of data points around the transition regions for approximately 50% and 100% reaction 
completion (times = 76 - 82s and time = 155s resepectively).  As can be seen in the images, the points appear to clearly 
aggregate around the transition region and, further, split into three distinctive regions around a large tungsten-trioxide-hydrate 
growth region.


# Time Evolution of Raw Data 

The second step of image processing involves evaluating the evolution of the tugsten-trioxide-hydrate layer over time. 
Differences in pixels of the image are plotted over time in an attempt to give information about what areas of the image change
in a major way. As the difference in time between images represents 1 second, these differences represent a first order 
derivative with time.  Once the regions of major change are pinpointed, this information will be used to narrow the regions 
of focus within the image for analysis.  As was mentioned earlier, the images do contain considerable noise (even after 
simple smoothing) that hinders computational analysis.

First, the pixel values (from rows 500 to 600) of each column of each picture are averaged; averaging occurs down a specific
column. There are 1024 columns for each image and so there are 1024 graphs, with each graph representing the average of a 
specific column of pixel values (e.g. column 1 of each image averaged over pixel rows 500 to 600) as y and the time as x.
As can be seenbelow, at low column numbers there is no trend.  The difference in average pixel values is relatively flat
which is as expected because from 0% completion to 100% completion, the tungsten does not change over time.  Moving right 
towards to middel sections of the image (e.g. pixel columns approximatel 350 - 600), noticable changes occurs as the transition layer
evolves with time. Between pixels columns of approximately 350 and 500, the data takes on an exponential shape and gradually evolves
towards the shape of a logistic function from approximately pixel columns 500 to 600. This indicates that for future analysis
we may want to localize the pixel columns for analysis to approximately columns 350 - 650.
<br>
<br>

Evolution of <b>columns 1-10</b> with time are shown below:

<iframe src="//www.slideshare.net/slideshow/embed_code/40270157" width="476" height="400" frameborder="0" marginwidth="0" marginheight="0" scrolling="no"></iframe>

<br>


Evolution of <b>columns 448-468</b> with time are shown below:

<iframe src="//www.slideshare.net/slideshow/embed_code/40270198" width="476" height="400" frameborder="0" marginwidth="0" marginheight="0" scrolling="no"></iframe>

<br>


Evolution of <b>columns 555-580</b> with time are shown below:

<iframe src="//www.slideshare.net/slideshow/embed_code/40270227" width="476" height="400" frameborder="0" marginwidth="0" marginheight="0" scrolling="no"></iframe>

<br>
<br>
<br>

## Peak Position Time Evolution

Another interesting trend is found is by ploting the location of the first time derivative peak over time; specifically the
maximum peak for a specific image (regardless of the column) where change is the most dramatic.  Over time, the location 
of the maximum time derivative peak has an almost linear downward trend while the maximum peak value for each image
has a linear trend of increase.

The results shown below are for location (column number) of the time derivative peak (for a specific image) over time:

!["Peak Position as a Function of Time"](http://i.imgur.com/2s5N7Cf.png "Peak Position as a Function of Time")

<br>

The results shown below are for maximum value of the time derivative peak (for a specific image) over time:

!["Peak Amplitude as a Function of Time"](http://i.imgur.com/7SwXpgx.png "Peak Amplitude as a Function of Time")

<br>

# Initial Attempts at Data Segmentation

For this trail run at segmentation, MATLAB codes developed by [Dr. Tom O'Haver ](http://terpconnect.umd.edu/~toh/) for 
peak fitting and [naive segmentation](https://gist.github.com/tonyfast/de3d7b841cea38dc40fa) code written by Tony Fast were used.
Different MATLAB filters and smoothing functions were used in tandem with these codes to smooth the data (e.g. MATLAB's 
imfilter in tandom with fspecial, imresize, wiener2).  The codes take in as inputs the image to be analyzed as well as:

1.  A user specified number of peaks - The program takes signals from the input image and attempts to decompose a complex
signal generated out of the image data into a user specified number (the number of peak inputs) of component signals.  This
is an attempt to see if the image data can be represented as a sum of more elementary signal functions with the peaks, in 
case, representing the boudaries of the transition layers.

2.  A user specified number of bins - The program divides the signals based off the intensities into a number (the number 
of bin inputs) of distributions to aid in the decomposition of the complex signal from the image data.

The number of peaks were varied between 3 and 8 and varied the number of bins from 10 to 1000.  For the initial attempt at
segmentation, the following inputs were used:

__{{site.data['segmentation']}}__

<br>
This image below is a result of the initial segmentation efforts with the image truncated to the area of interest. At this
point segmentation was applied to the entire image, butfuture work will trucate the image using previous analysis outcomes 
before segmenting the image to try and better fit the data; as has been mentioned, residual noise in the data is greatly
affecting segmentation outcomes (even with smoothing) and some of the image must be removed:

![Segmentation Image](http://i.imgur.com/MH8CuxO.jpg "Segmentation image ran with 7 peaks and 250 bins")

<br>


As was mentioned, the image has been cropped to focus on a region of interest; that region which is susptected to be 
the evolvoing tri-oxide hydrate layer.  For comparison sake, here is the orinal image deliniating the area of interest.

<br>

!["Original image showing area of interest"](http://i.imgur.com/dExZKTw.jpg "Original image showing area of interest")


<br><br>

As can be seen, the peak finding and fitting have some not so nice errors with conditions input.  Again, it is suspected that
the residual noise in the image is greatly affecting segmentation efforts:

<br>

!["Segmentation Histogram"](http://i.imgur.com/RN7GadD.jpg "Segmentation histogram plot ran with 7 peaks and 250 bins")


<br>

## How does this relate to what has been done?

In reference to the segmented image, the image below represents the origianl image overlayed with the first spatial
derivative.  When compared to the segmented image, there is a nice visual fit indicating the transition region. 

<br>


!["Original Data with Derivatve"](http://i.imgur.com/b3I9KD6.jpg "Original Image Overlayed with First Derivative Data at t=155s")


<br>

It is interesting to note that whether the numerical derivatives are applied over the data or segmentation algorithm,
a simialar trend is found in this tri-oxide hydrate layer/transition region.   Also interesting to note is that the data 
seems to indicate multi-layering which, based off the electron transmission intesities, could indicate multi-phase regions.

## What is next?

 -  We want to truncate the images and focus on narrower bands around the transition region before running analysis.  We hope this will eliminate 
 some of the errors we are getting in the segmentaiton outputs.  This task will be a little complicated as the number of peaks and bins
 for the segmentation algorithm will change along with the data.  
 -  We then will begin running n-point statistics and correlations
 
 These steps will take some time, so we do not have a working time frame on the length of these tasks.  Further updates will be
 put together and provided after these steps.  Please let us know if you have any questions or have any feedback.
